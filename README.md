# ğŸ§  Intelligent Evaluation System (æ™ºèƒ½è¯„ä»·ç³»ç»Ÿ)


> A Chinese text sentiment analysis system based on **PyTorch + GRU**.  
> ä¸€ä¸ªåŸºäº **PyTorch + GRU** çš„ä¸­æ–‡æ–‡æœ¬æƒ…æ„Ÿåˆ†æç³»ç»Ÿï¼Œç”¨äºè‡ªåŠ¨è¯†åˆ«æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ã€‚

---

## ğŸ“š Overview | é¡¹ç›®ç®€ä»‹

**Intelligent Evaluation System** aims to build a lightweight yet powerful **Chinese text sentiment classification** model using GRU (Gated Recurrent Unit).  
The system can automatically evaluate and classify text polarity (positive/negative) and is suitable for applications in:
- ğŸ›’ E-commerce review analysis  
- ğŸ“° Public opinion monitoring  
- ğŸ’¬ Intelligent customer service  
- ğŸ§‘â€ğŸ« Education and psychological evaluation

---

## ğŸ§© Project Structure | é¡¹ç›®ç»“æ„
```text
Intelligent-Evaluation-System/
â”œâ”€ .gitignore
â”œâ”€ LICENSE
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ data/
â”‚  â”œâ”€ processed/
â”‚  â””â”€ raw/
â”œâ”€ logs/
â”œâ”€ models/
â””â”€ src/
   â”œâ”€ config.py
   â”œâ”€ dataset.py
   â”œâ”€ evaluate.py
   â”œâ”€ model.py
   â”œâ”€ predict.py
   â”œâ”€ process.py
   â”œâ”€ train.py
   â””â”€ utils.py
```
---

## âš™ï¸ Environment Setup | ç¯å¢ƒé…ç½®

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Jz17777/Intelligent-Evaluation-System.git
cd Intelligent-Evaluation-System
```
### 2ï¸âƒ£ Create virtual environment and install dependencies
```bash
conda create -n evalsys python=3.10
conda activate evalsys
pip install -r requirements.txt
```

---

## ğŸ”„ Model Training | æ¨¡å‹è®­ç»ƒ

You can switch between GRU / LSTM / RNN using the --arch argument:

```bash
# Train GRU model (default)
python src/train.py --arch GRU

# Train LSTM model
python src/train.py --arch LSTM

# Train RNN model
python src/train.py --arch RNN
```

Training process will automatically:

Display training & validation loss / accuracy

Save the best model under models/best_GRU_model.pt

Log training metrics to logs/ for visualization

---

## Model Evaluation | æ¨¡å‹è¯„ä¼°
After training, you can evaluate your model performance on the validation or test dataset using:
```bash
# Evaluate GRU model (default)
python src/evaluate.py --arch GRU

# Evaluate LSTM model
python src/evaluate.py --arch LSTM

# Evaluate RNN model
python src/evaluate.py --arch RNN
```
This script will:

Load the best trained model (models/best_GRU_model.pt)

Evaluate performance metrics such as:

âœ… Accuracy

ğŸ¯ Precision

ğŸ” Recall

ğŸ§® F1-score

Optionally generate a confusion matrix for analysis

## ğŸ“Š Visualization with TensorBoard | å¯è§†åŒ–

You can monitor model performance using TensorBoard:

```bash
tensorboard --logdir=logs
```

Then open in your browser: ğŸ‘‰ http://localhost:6006

---
## ğŸ§  Prediction | æ¨¡å‹é¢„æµ‹
To perform batch predictions using the trained model:
```bash
# Predict GRU model
python src/predict.py --arch GRU

# Predict LSTM model
python src/predict.py --arch LSTM

# Predict RNN model
python src/predict.py --arch RNN
```

---
## ğŸ“ Directory Summary | æ–‡ä»¶ç›®å½•è¯´æ˜

| Folder  | Description |
|----------------|------|
| `data/` | Stores raw and processed datasets (excluded from GitHub) |
| `models/` | Model saving directory (e.g., best_GRU_model.pt) |
| `logs/` | TensorBoard logs for visualization |
| `src/` | Core source code directory |

---
## ğŸ’¡ Configuration | å‚æ•°é…ç½®ï¼ˆconfig.pyï¼‰

You can modify training hyperparameters in src/config.py:
```bash
EPOCHS = 10
BATCH_SIZE = 64
LEARNING_RATE = 1e-3
EMBEDDING_DIM = 128
HIDDEN_DIM = 256
NUM_LAYERS = 2
BIDIRECTIONAL = True
```
---
## ğŸ§‘â€ğŸ’» Author Information | ä½œè€…ä¿¡æ¯

Author: Christopher Zhou(Jz17777)  
Email: christopherzjz@outlook.com  
University: University of Glasgow, James Watt School of Engineering  
Language: Python 3.10, PyTorch 2.x  
